# -*- coding: utf-8 -*-
"""AL code better vis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vk1IjayPMzYIegWKX4BRje07Jzx6rxet

# **Dataset Description**

The dataset is designed for ransomware detection using machine learning techniques. It includes system calls (API usage patterns) collected from:

* 270 ransomware samples from 12 families (e.g., WannaCry, Petya, TeslaCrypt, etc.).
* 270 benignware samples from diverse categories like file compression, multimedia tools, and networking utilities.

**Structure:**

* It contains 5194 features (columns) representing distinct API calls or system call frequencies.
* 540 rows Each row corresponds to a single application sample, either benign or ransomware.
"""

# Import necessary libraries
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
from sklearn.feature_selection import VarianceThreshold
from scipy.sparse import csr_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load and clean the dataset
df = pd.read_csv('structured_dataset (2).csv')
df.columns = df.columns.str.strip().str.replace(
    r"\\t+", "", regex=True)  # Clean column names
df.set_index('System Calls', inplace=True)  # Set 'System Calls' as index

print("\nOriginal Dataset Preview:")
print(df.head())

# Feature Selection: Remove low-variance features
# Keep features with variance > 0.01
selector = VarianceThreshold(threshold=0.01)
reduced_data = selector.fit_transform(df)

selected_features = df.columns[selector.get_support()]  # Selected column names

print(f"\nNumber of features after feature selection: {
      len(selected_features)}")
print(f"Selected features: {selected_features[:10].tolist()} (first 10 shown)")

# Convert reduced data to DataFrame
df_reduced = pd.DataFrame(
    reduced_data, columns=selected_features, index=df.index)

# Convert numerical data to binary (presence/absence)
binary_data = (df_reduced > 0).astype(bool)
print(binary_data)

# Convert dataset to sparse format to optimize memory usage
sparse_data = csr_matrix(binary_data)
print(sparse_data)

# Apply Apriori Algorithm with increased min_support
frequent_itemsets = apriori(
    binary_data, min_support=0.1, use_colnames=True, max_len=2)
print("\nFrequent Itemsets Found:")
print(frequent_itemsets.head())

# Calculate the number of itemsets
num_itemsets = len(frequent_itemsets)
print(f"\nTotal number of frequent itemsets: {num_itemsets}")

# Generate Association Rules
print("\nGenerating association rules...")
rules = association_rules(frequent_itemsets, metric="confidence",
                          min_threshold=0.5, num_itemsets=num_itemsets)
print("\nAssociation Rules Preview:")
print(rules[['antecedents', 'consequents',
      'support', 'confidence', 'lift']].head())

# Select Top 10 Rules based on Lift
top_rules = rules.sort_values(by='lift', ascending=False).head(10)

# Visualization: Bar plot of top rules
print("\nVisualizing the top 10 association rules...")
plt.figure(figsize=(10, 6))
sns.barplot(
    x=top_rules['lift'],
    y=top_rules['consequents'].apply(lambda x: ', '.join(list(x))),
    palette='viridis'
)
plt.title('Top 10 Association Rules by Lift')
plt.xlabel('Lift')
plt.ylabel('Consequents')
plt.tight_layout()
plt.show()

# Visualization: Heatmap for support and confidence
print("\nCreating a heatmap for support, confidence, and lift of the top rules...")
heatmap_data = top_rules[['support', 'confidence', 'lift']].set_index(
    top_rules['consequents'].apply(lambda x: ', '.join(list(x)))
)
plt.figure(figsize=(8, 5))
sns.heatmap(heatmap_data, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Top Association Rules')
plt.ylabel('Consequents')
plt.tight_layout()
plt.show()

# Display Summary of Analysis
print("\nSummary of Analysis:")
print(f"- Initial number of features: {df.shape[1]}")
print(f"- Number of features after selection: {len(selected_features)}")
print(f"- Number of frequent itemsets found: {num_itemsets}")
print(f"- Top 10 rules based on lift:\n{
      top_rules[['antecedents', 'consequents', 'lift']].to_string(index=False)}")
